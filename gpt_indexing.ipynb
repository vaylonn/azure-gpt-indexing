{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index import LangchainEmbedding\n",
    "from llama_index import download_loader\n",
    "from llama_index import (\n",
    "    GPTVectorStoreIndex,\n",
    "    SimpleDirectoryReader, \n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Chargement des variables d'environnement depuis le fichier .env\n",
    "load_dotenv('./.env')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration de l'API OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'API OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_base = \"https://innoopenai.openai.azure.com/\"\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set context window\n",
    "context_window = 4096\n",
    "\n",
    "#set number of output tokens\n",
    "num_output = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de l'objet AzureOpenAI\n",
    "# test1 représente le nom de déployment model sur Azure (le nom du modèle gpt35turbo)\n",
    "llm = AzureChatOpenAI(deployment_name=\"test1\", temperature=0.1, max_tokens=num_output, openai_api_version=openai.api_version, model_kwargs={\n",
    "    \"api_key\": openai.api_key,\n",
    "    \"api_base\": openai.api_base,\n",
    "    \"api_type\": openai.api_type,\n",
    "    \"api_version\": openai.api_version,\n",
    "})\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "\n",
    "# Initialisation de l'objet LangchainEmbedding pour l'indexation des documents à partir ici du modèle ada-002 nommé ada-test dans Azureembedding_llm = LangchainEmbedding(\n",
    "embedding_llm = LangchainEmbedding(\n",
    "    OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        deployment=\"ada-test\",\n",
    "        openai_api_key= openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_type=openai.api_type,\n",
    "        openai_api_version=openai.api_version,\n",
    "    ),\n",
    "    embed_batch_size=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdf, txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 8c6e9d0c-7ec9-4707-9783-8ea56d2b3b22\n",
      "Loaded doc with 33 pages\n"
     ]
    }
   ],
   "source": [
    "# Chargement des documents à partir du répertoire './data'\n",
    "documents = SimpleDirectoryReader('./data').load_data()\n",
    "#permet de vérifier que les docs ont bien étés chargés\n",
    "print('Document ID:', documents[0].doc_id)\n",
    "print((f\"Loaded doc with {len(documents)} pages\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load qu'une seule page d'un site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BeautifulSoupWebReader = download_loader(\"BeautifulSoupWebReader\")\n",
    "loader = BeautifulSoupWebReader()\n",
    "documents = loader.load_data(urls=['https://www.equans.fr/'])\n",
    "#permet de vérifier que les docs ont bien étés chargés\n",
    "print('Document ID:', documents[0].doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor,\n",
    "    embed_model=embedding_llm,\n",
    "    context_window=context_window,\n",
    "    num_output=num_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building doc n°1 index with 41 nodes\n"
     ]
    }
   ],
   "source": [
    "# Création de l'index à partir des documents et du service_context\n",
    "index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "index.storage_context.persist(persist_dir=\"./storage\")\n",
    "print((f\"Finished building doc n°1 index with {len(index.docstore.docs)} nodes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de l'index à partir du stockage\n",
    "from llama_index import load_index_from_storage\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "index = load_index_from_storage(storage_context, service_context=service_context)\n",
    "print((f\"Finished loading doc n°1 index from storage with {len(index.docstore.docs)} nodes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Prompt\n",
    "template = (\n",
    "    \"Tu trouveras ci-dessous des informations contextuelles. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Tu es un assistant technique de la socitété Equans via un chatbot. Tu donnes une assistance technique aux questions que te poseras l'utilisateur.\"\n",
    "    \"D'après le contexte, réponds à la question en français uniquement, même si la question est posée dans une autre langue. Réponds donc à la question:{query_str}\\n\"\n",
    "    \"Il se peut que l'utilisateur te pose des questions sur des parties spécifiques du document. Essaye de les retrouver et de répondre à la question\"\n",
    "    \"Si la question n'a rien à voir avec les documents, réponds simplement : 'Je suis désolé, je n'ai pas pu trouver la réponse dans les documents que vous m'avez donné.' sauf si on te demande des questions sur toi(ex: Bonjour ou qui es-tu ?).\"\n",
    ")\n",
    "qa_template = Prompt(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisateur: de quoi parle ce document ?\n",
      "EquansGPT: Ce document parle des ondes électromagnétiques et de leurs applications dans différents systèmes tels que la sécurité, la détection d'objets en mouvement, la cartographie et la localisation d'objets dans des environnements à faible visibilité. Il explique également le phénomène d'écho utilisé dans la détection d'objets à l'aide de faisceaux lumineux.\n"
     ]
    }
   ],
   "source": [
    "# Requête envoyée au modèle\n",
    "context = \"ce document est un rapport sur les systèmes de repérage et de détresse\"\n",
    "query = \"de quoi parle ce document ?\"\n",
    "query_engine = index.as_query_engine(similarity_top_k=3, text_qa_template=qa_template)\n",
    "answer = query_engine.query(query)\n",
    "\n",
    "# Affichage des résultats\n",
    "#print(answer.get_formatted_sources())\n",
    "print('Utilisateur:', query)\n",
    "print('EquansGPT:', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Text:\t une  meilleure compréhension et à une utilisation optimisée de ces systèm es pour la sécurité et le  bien-être de tous. ...\n",
      "Metadata:\t {'page_label': '4', 'file_name': 'Rapport bibliographique AZOULAY_BERI_DELANGLE.pdf'}\n",
      "Score:\t 0.829\n",
      "-----\n",
      "Text:\t maladies.   De l’autre côté, les ondes au -dessus de la lumière visible (infrarouges, micro -ondes et  radios) ont de nombreuses applications dans les systèmes de repérages et de détresse. On les  utilise notamment dans la transmission d’informations, la détection d’objets en mouvements,  dans la cartographie, la localisation d’objets dans des environnements à faible visibilité. ...\n",
      "Metadata:\t {'page_label': '9', 'file_name': 'Rapport bibliographique AZOULAY_BERI_DELANGLE.pdf'}\n",
      "Score:\t 0.810\n",
      "-----\n",
      "Text:\t de faisceaux par seconde sur une surface qui les réfléchit  et revient à sa s ource. On mesure ensuite le temps que met la lumière à revenir vers lui. C’est  ce qu’on appelle le phénomène d’écho. Plus l’écho est fort, plus l’objet est proche. Le premier  écho perçu représente l’objet le plus proche.  Ensuite, les échos suivants, de moi ns en moins  fort, définissent des objets de plus en plus loin. ...\n",
      "Metadata:\t {'page_label': '10', 'file_name': 'Rapport bibliographique AZOULAY_BERI_DELANGLE.pdf'}\n",
      "Score:\t 0.806\n"
     ]
    }
   ],
   "source": [
    "for node in answer.source_nodes:\n",
    "    print('-----')\n",
    "    text_fmt = node.node.text.strip().replace('\\n', ' ')[:1000]\n",
    "    print(f\"Text:\\t {text_fmt} ...\")\n",
    "    print(f'Metadata:\\t {node.node.extra_info}')\n",
    "    print(f'Score:\\t {node.score:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
